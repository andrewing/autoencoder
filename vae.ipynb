{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No Cuda Available\")\n",
    "device  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = torchvision.transforms.Compose([\n",
    "  torchvision.transforms.ToTensor(),\n",
    "  # torchvision.transforms.Lambda(lambda x: torch.flatten(x))\n",
    "])\n",
    "train_set = torchvision.datasets.MNIST(\"mnist_data\", train=True, download=True, transform=T)\n",
    "print(train_set)\n",
    "test_set = torchvision.datasets.MNIST(\"mnist_data\", train=False, download=True, transform=T)\n",
    "print(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_dl = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(test_set, batch_size = 1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_set[0][0][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Auto Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_VAE(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kl = 0\n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "        self.N.loc = self.N.loc.cuda()\n",
    "        self.N.scale = self.N.scale.cuda()\n",
    "\n",
    "        self.encoder_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.encoder_dense = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3 * 3 * 32, 128),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.bottleneck1 = nn.Linear(128, 2)\n",
    "        self.bottleneck2 = nn.Linear(128, 2)\n",
    "\n",
    "        self.decoder_dense = nn.Sequential(\n",
    "            nn.Linear(2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 3*3*32),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, [32, 3, 3])\n",
    "        )\n",
    "\n",
    "        self.decoder_maxunpool = nn.MaxUnpool2d(2)\n",
    "\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_conv = self.encoder_conv(x)\n",
    "        encoder_dense = self.encoder_dense(encoder_conv)\n",
    "\n",
    "        mu = self.bottleneck1(encoder_dense)\n",
    "        sigma = torch.exp(self.bottleneck2(encoder_dense))\n",
    "        z = mu + sigma*self.N.sample(mu.shape)\n",
    "        self.kl = (sigma**2 + mu**2 - torch.log(sigma) - 1/2).sum()\n",
    "\n",
    "        decoder_dense = self.decoder_dense(z)\n",
    "        decoder_conv = self.decoder_conv(decoder_dense)\n",
    "        return decoder_conv, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANTIATE NEW\n",
    "LOAD = False\n",
    "vae = None\n",
    "if LOAD:\n",
    "  vae = torch.load(\"vae.pt\")\n",
    "  print(vae.eval())\n",
    "else:\n",
    "  vae = MNIST_VAE()\n",
    "  print(vae.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "EPOCHS = 100\n",
    "vae = vae.to(device)\n",
    "optimizer = torch.optim.Adam(vae.parameters(),\n",
    "                             lr = 1e-3,\n",
    "                             weight_decay = 1e-5)\n",
    "\n",
    "for i in tqdm(range(EPOCHS)):\n",
    "  sum_loss = 0 \n",
    "  ctr = 0\n",
    "  for j, (images, labels) in tqdm(enumerate(train_dl)):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    pred, bottlenecked = vae(images)\n",
    "\n",
    "    #DISPLAY IMAGE\n",
    "    if j == 0 and i % 5 == 0:\n",
    "      plt.imshow(torch.squeeze(images)[0].cpu(), cmap=\"gray\")\n",
    "      plt.show()\n",
    "      plt.imshow(torch.Tensor.cpu(torch.squeeze(pred[0])).detach().numpy(), cmap = \"gray\")\n",
    "      plt.show()\n",
    "\n",
    "    #MSE\n",
    "    loss = ((images - pred)**2).sum() + vae.kl\n",
    "    \n",
    "    #GRADIENT DESCENT\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    #LOSS LOG\n",
    "    sum_loss += loss.item()\n",
    "    ctr += 1\n",
    "  print(sum_loss/ctr)\n",
    "\n",
    "torch.save(vae, \"vae.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_samples = []\n",
    "for sample in tqdm(test_set):\n",
    "    img = sample[0].unsqueeze(0).to(device)\n",
    "    label = sample[1]\n",
    "    # Encode image\n",
    "    vae.eval()\n",
    "    with torch.no_grad():\n",
    "       _, encoded_img  = vae(img)\n",
    "    # Append to list\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    encoded_sample['label'] = label\n",
    "    encoded_samples.append(encoded_sample)\n",
    "    \n",
    "encoded_samples = pd.DataFrame(encoded_samples)\n",
    "encoded_samples\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "\n",
    "px.scatter(encoded_samples, x='Enc. Variable 0', y='Enc. Variable 1', color=encoded_samples.label.astype(str), opacity=0.7, width=800, height=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ae_outputs(vae ,n=10):\n",
    "    plt.figure(figsize=(16,4.5))\n",
    "    targets = test_set.targets.numpy()\n",
    "    t_idx = {i:np.where(targets==i)[0][0] for i in range(n)}\n",
    "    for i in range(n):\n",
    "      ax = plt.subplot(2,n,i+1)\n",
    "      img = test_set[t_idx[i]][0].unsqueeze(0).to(device)\n",
    "      with torch.no_grad():\n",
    "         rec_img, _  = vae(img)\n",
    "      plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "        ax.set_title('Original images')\n",
    "      ax = plt.subplot(2, n, i + 1 + n)\n",
    "      plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "      ax.get_xaxis().set_visible(False)\n",
    "      ax.get_yaxis().set_visible(False)  \n",
    "      if i == n//2:\n",
    "         ax.set_title('Reconstructed images')\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ae_outputs(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f04ad673eb082f246261ed3726fd8520b4b2a725686c2e40db64bd825d301ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
